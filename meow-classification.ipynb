{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU:0: GeForce GTX 1070\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os,sys\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "if(torch.cuda.is_available()):\n",
    "    print(f\"GPU:{torch.cuda.current_device()}: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_speech_features import mfcc\n",
    "from python_speech_features import logfbank\n",
    "import scipy.io.wavfile as wav\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 127, 1: 92, 2: 221}\n",
      "92\n",
      "276\n",
      "{2: 92, 1: 92, 0: 92}\n"
     ]
    }
   ],
   "source": [
    "def get_label(fn):\n",
    "        '''\n",
    "        Files containing meows are in the dataset.zip archive. They are PCM streams (.wav).\n",
    "        Naming conventions follow the pattern C_NNNNN_BB_SS_OOOOO_RXX, which has to be exploded as follows:\n",
    "\n",
    "            C = emission context (values: B = brushing; F = waiting for food; I: isolation in an unfamiliar environment);\n",
    "            NNNNN = cat’s unique ID;\n",
    "            BB = breed (values: MC = Maine Coon; EU: European Shorthair);\n",
    "            SS = sex (values: FI = female, intact; FN: female, neutered; MI: male, intact; MN: male, neutered);\n",
    "            OOOOO = cat owner’s unique ID;\n",
    "            R = recording session (values: 1, 2 or 3)\n",
    "            XX = vocalization counter (values: 01..99)\n",
    "        example: B_BRI01_MC_FI_SIM01_202\n",
    "            \n",
    "        '''\n",
    "        em={}\n",
    "        em['B']=0\n",
    "        em['F']=1\n",
    "        em['I']=2\n",
    "        fn_explode = fn.split(\"_\")\n",
    "        em_letter = fn_explode[0]\n",
    "        return em[em_letter]\n",
    "\n",
    "d={}\n",
    "rootdir=r'data\\meow'\n",
    "dirs=os.listdir(rootdir)\n",
    "for filename in dirs:\n",
    "    label = get_label(filename)\n",
    "    if(label not in d):\n",
    "        d[label]=0\n",
    "    d[label]+=1\n",
    "print(d)\n",
    "print(min(d.values()))    \n",
    "#need to balance\n",
    "min_val=min(d.values())\n",
    "random.seed(2334)\n",
    "random.shuffle(dirs)\n",
    "d={}\n",
    "dirs_dataset=[]\n",
    "for filename in dirs:\n",
    "    label = get_label(filename)\n",
    "    if(label not in d):\n",
    "        d[label]=0\n",
    "    if(d[label]<min_val):\n",
    "    #if(True):\n",
    "        d[label]+=1\n",
    "        dirs_dataset.append(filename)\n",
    "print(len(dirs_dataset))\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features=102400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102400,)\n",
      "(102400,)\n",
      "(102400,)\n",
      "(102400,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Drake Li\\dsvenv1\\lib\\site-packages\\ipykernel_launcher.py:25: WavFileWarning: Chunk (non-data) not understood, skipping it.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#load data\n",
    "def chunk_train_generator(filenames, chunksize=n_features,rootdir=r'data\\meow',maxbytes=n_features):\n",
    "    \"\"\"\n",
    "    cutoff files at 100KB\n",
    "    \"\"\"\n",
    "    def expand_filename(x,depth=4):\n",
    "        return os.path.join(*tuple([rootdir] + [x[i:i+2] for i in range(0,2*depth,2)] + [x]))\n",
    "    \n",
    "    def expand_sample(x):\n",
    "        N = len(x)\n",
    "        x = np.asarray(x)\n",
    "        if N <= chunksize:\n",
    "            rem = np.zeros(chunksize-N,dtype=np.uint16)\n",
    "            x = np.concatenate((x,rem))\n",
    "        return x\n",
    "    \n",
    "    #dirs=os.listdir(rootdir)\n",
    "    \n",
    "    while(True):\n",
    "        \n",
    "        for filename in filenames:\n",
    "\n",
    "            label = get_label(filename)\n",
    "            fullpath=os.path.join(rootdir,filename)\n",
    "            (rate,sig) = wav.read(fullpath)\n",
    "            mfcc_feat = mfcc(sig,rate)\n",
    "            fbank_feat = logfbank(sig,rate)\n",
    "\n",
    "            #print(fbank_feat[1:3,:])\n",
    "            bin_content =  np.fromfile(\n",
    "                                fullpath,\n",
    "                                dtype=np.uint8,\n",
    "                                count=int(maxbytes),\n",
    "                                ).astype(dtype=np.uint16)\n",
    "            #print(bin_content.shape)\n",
    "            yield expand_sample(fbank_feat.reshape(-1)), np.asarray([label])\n",
    "        \n",
    "for i,item in enumerate(chunk_train_generator(dirs_dataset)):\n",
    "    print(item[0].shape)\n",
    "    #break\n",
    "    if(i==3):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Meow_CNN(nn.Module):\n",
    "    def __init__(self,use_dropout=False, use_bn=False):\n",
    "        super().__init__()\n",
    "        self.use_bn=use_bn\n",
    "        self.use_dropout=use_dropout\n",
    "        self.embed = torch.nn.Embedding(128,10)\n",
    "        \n",
    "        self.activation = torch.nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        \n",
    "        self.conv1 = torch.nn.Conv1d(10,out_channels=96, kernel_size=11, stride=1)\n",
    "        self.max1 = torch.nn.MaxPool1d(2, stride=2)\n",
    "        self.bn1 = nn.BatchNorm1d(96)\n",
    "        \n",
    "        self.conv2 = torch.nn.Conv1d(96,out_channels=96, kernel_size=5, stride=1)\n",
    "        self.max2 = torch.nn.MaxPool1d(2, stride=2)\n",
    "        self.bn2 = nn.BatchNorm1d(96)\n",
    "        \n",
    "        self.conv3 = torch.nn.Conv1d(96,out_channels=96, kernel_size=5, stride=1)\n",
    "        self.max3 = torch.nn.MaxPool1d(2, stride=2)\n",
    "        self.bn3 = nn.BatchNorm1d(96)\n",
    "        \n",
    "        self.conv4 = torch.nn.Conv1d(96,out_channels=256, kernel_size=5, stride=1)\n",
    "        self.max4 = torch.nn.MaxPool1d(2, stride=2)\n",
    "        self.bn4 = nn.BatchNorm1d(256)\n",
    "        \n",
    "        self.conv5 = torch.nn.Conv1d(256,out_channels=512, kernel_size=5, stride=1)\n",
    "        self.max5 = torch.nn.MaxPool1d(2, stride=2)\n",
    "        self.bn5 = nn.BatchNorm1d(512)\n",
    "        \n",
    "        self.conv6 = torch.nn.Conv1d(256,out_channels=256, kernel_size=5, stride=1)\n",
    "        self.max6 = torch.nn.MaxPool1d(2, stride=2)\n",
    "        self.bn6 = nn.BatchNorm1d(256)\n",
    "        \n",
    "        self.conv7 = torch.nn.Conv1d(256,out_channels=96, kernel_size=5, stride=1)\n",
    "        self.max7 = torch.nn.MaxPool1d(2, stride=2)\n",
    "        self.bn7 = nn.BatchNorm1d(96)\n",
    "        \n",
    "        self.conv8 = torch.nn.Conv1d(96,out_channels=512, kernel_size=5, stride=1)\n",
    "        self.max8 = torch.nn.MaxPool1d(2, stride=2)\n",
    "        self.bn8 = nn.BatchNorm1d(512)\n",
    "        \n",
    "        self.gmax1 = torch.nn.AdaptiveMaxPool1d(1)\n",
    "        self.gavg1 = torch.nn.AdaptiveAvgPool1d(1)\n",
    "        \n",
    "        self.catstate_output = nn.Sequential(nn.Linear(512,512,bias=True),\n",
    "                                             nn.ReLU(),\n",
    "                                             nn.Dropout(p=0.1, inplace=False),\n",
    "                                             nn.Linear(512,3,bias=True)\n",
    "                                             ).to(device)\n",
    "\n",
    "        \n",
    "    def forward(self,inp):\n",
    "        \n",
    "        x = self.embed(inp)\n",
    "        x = torch.transpose(x,1,2)\n",
    "        print(x.shape)\n",
    "        x = self.conv1(x)\n",
    "        x = self.max1(x)\n",
    "        x = self.activation(x)\n",
    "        if self.use_bn:\n",
    "            x = self.bn1(x)\n",
    "        if self.use_dropout:\n",
    "            x = self.dropout(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.max2(x)\n",
    "        x = self.activation(x)\n",
    "        if self.use_bn:\n",
    "            x = self.bn2(x)\n",
    "        if self.use_dropout:\n",
    "            x = self.dropout(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.max3(x)\n",
    "        x = self.activation(x)\n",
    "        if self.use_bn:\n",
    "            x = self.bn3(x)\n",
    "        if self.use_dropout:\n",
    "            x = self.dropout(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.max4(x)\n",
    "        x = self.activation(x)\n",
    "        if self.use_bn:\n",
    "            x = self.bn4(x)\n",
    "        if self.use_dropout:\n",
    "            x = self.dropout(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = self.activation(x)\n",
    "\n",
    "        #xmax = self.gmax1(x)\n",
    "        xavg = self.gavg1(x)\n",
    "\n",
    "        \n",
    "        #merge = torch.cat((xmax, xavg), 1)\n",
    "        x = xavg\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.activation(x)\n",
    "        out = self.catstate_output(x)\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(data.Dataset):\n",
    "\n",
    "    def __init__(self,filenames, chunksize=n_features,maxbytes=n_features,rootdir=r'data\\meow'):\n",
    "\n",
    "        self.gen = chunk_train_generator(filenames=filenames,\n",
    "                                        chunksize=chunksize,\n",
    "                                        rootdir=rootdir,maxbytes=maxbytes)\n",
    "        \n",
    "        self.length = len(filenames)\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        sample,label = next(self.gen)\n",
    "        return sample.astype(np.int),label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss functions\n",
    "\n",
    "# def poisson_loss(ypred,ytrue,eps=1e-6):\n",
    "#     return torch.mean(ypred-ytrue*torch.log(ypred+eps))\n",
    "# def cross_entropy(ypred,ytrue):\n",
    "#     #print(ypred)\n",
    "#     #print(ytrue)\n",
    "#     return F.binary_cross_entropy(ypred,ytrue)\n",
    "\n",
    "def compute_loss(predictions,labels):\n",
    "    #print(type(labels[0]))\n",
    "    \n",
    "    #labels=labels.type(torch.LongTensor).cuda().squeeze()\n",
    "\n",
    "    #criterion = nn.CrossEntropyLoss() \n",
    "    loss = F.cross_entropy(predictions.squeeze(),labels.type(torch.LongTensor).cuda().squeeze())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def get_accuracy(logit, target, batch_size):\n",
    "    ''' Obtain accuracy for training round '''\n",
    "    # torch.max[0] stores the data, torch.max[1] stores the index (of the max)\n",
    "    preds=torch.max(logit, 1)[1].view(target.size())\n",
    "    \n",
    "    print(preds.squeeze().data.tolist())\n",
    "    print(target.squeeze().data.tolist())\n",
    "    #print(target.data)\n",
    "    corrects = (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()\n",
    "    accuracy = 100.0 * corrects/batch_size\n",
    "    \n",
    "    return accuracy.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_model(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Running pytorch training loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Drake Li\\dsvenv1\\lib\\site-packages\\ipykernel_launcher.py:25: WavFileWarning: Chunk (non-data) not understood, skipping it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples shape: torch.Size([10, 102400])\n",
      "input Cuda: True\n",
      "torch.Size([10, 10, 102400])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuDNN error: CUDNN_STATUS_INTERNAL_ERROR",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-836f9cc0e43b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34mf'epoch_{epoch}.pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-836f9cc0e43b>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(n_epochs, batch_size, output_dir)\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m             \u001b[1;31m#print(labels)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\dsvenv1\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-94f3970afae2>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inp)\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\dsvenv1\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\dsvenv1\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 298\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\dsvenv1\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    293\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[0;32m    294\u001b[0m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[1;32m--> 295\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "def train(n_epochs=6,batch_size=10,output_dir=r'models'):\n",
    "    \n",
    "    print(\"[INFO] Running pytorch training loop\")\n",
    "    dataset = TrainDataset(filenames=dirs_dataset)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, sampler=None,\n",
    "                       batch_sampler=None, collate_fn=None,\n",
    "                       pin_memory=False, drop_last=False, timeout=0,\n",
    "                       worker_init_fn=None)\n",
    "    net = Meow_CNN(use_dropout=False,use_bn=False).cuda()\n",
    "    start_epoch = 0\n",
    "    #maybe other optimizers\n",
    "    opt = torch.optim.SGD(net.parameters(),lr=0.01,momentum=0.9)\n",
    "    #opt = torch.optim.Adam(net.parameters())\n",
    "    loss_avg_queue=[]\n",
    "    acc_avg_queue=[]\n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        for i,sample_batch in enumerate(dataloader):\n",
    "            samples,labels = sample_batch\n",
    "            samples = samples.cuda()\n",
    "            net=net.train()\n",
    "            if i == 0:\n",
    "                print(f\"samples shape: {samples.shape}\")\n",
    "                print(f\"input Cuda: {samples.is_cuda}\")\n",
    "            \n",
    "            labels = labels.cuda()\n",
    "            \n",
    "            out = net(samples)\n",
    "            #print(labels)\n",
    "            loss = compute_loss(out,labels)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            acc = get_accuracy(out,labels,batch_size)\n",
    "            \n",
    "            loss_avg_queue.append(loss.item())\n",
    "            acc_avg_queue.append(acc)\n",
    "            if len(loss_avg_queue) > 10:\n",
    "                loss_avg_queue = loss_avg_queue[1:]\n",
    "                acc_avg_queue = acc_avg_queue[1:]\n",
    "            loss_avg = np.mean(loss_avg_queue)\n",
    "            acc_avg = np.mean(acc_avg_queue)\n",
    "            print(f'\\r Epoch: {epoch}/{n_epochs} Iter: {i+1}/{len(dataloader)} Loss: {round(loss_avg,5)} Acc: {round(acc_avg,5)}')\n",
    "            #print(f\"acc={acc}, labels={labels}\")\n",
    "            \n",
    "            net.eval()\n",
    "        #print(\"sum:\")\n",
    "        #print(out)\n",
    "        #print(labels)\n",
    "        print(f'...writing out model for epoch {epoch}')\n",
    "        torch.save(net.state_dict(), os.path.join(output_dir,f'epoch_{epoch}.pt'))\n",
    "        break\n",
    "train()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsvenv",
   "language": "python",
   "name": "dsvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
